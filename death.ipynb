{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6027e2eb",
   "metadata": {},
   "source": [
    "# COVID-19 Malaysia Data Preprocessing & Splitting\n",
    "\n",
    "This notebook processes Malaysia’s COVID-19 datasets (cases, deaths, hospital, ICU, tests, vaccination), merges them, creates lag features, filters a specific date range, shuffles the rows, and splits the data into **5 training sets** and **1 testing set**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef6cbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# Import libraries\n",
    "# ========================\n",
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d634c14",
   "metadata": {},
   "source": [
    "## Load CSV Files\n",
    "\n",
    "We import datasets from CSV files and parse the `date` column as datetime.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4e1e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = pd.read_csv(\"cases_malaysia.csv\", parse_dates=[\"date\"])\n",
    "deaths = pd.read_csv(\"deaths_malaysia.csv\", parse_dates=[\"date\"])\n",
    "hospital = pd.read_csv(\"hospital.csv\", parse_dates=[\"date\"])\n",
    "icu = pd.read_csv(\"icu.csv\", parse_dates=[\"date\"])\n",
    "tests = pd.read_csv(\"tests_malaysia.csv\", parse_dates=[\"date\"])\n",
    "vax = pd.read_csv(\"vax_malaysia.csv\", parse_dates=[\"date\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb12cf6c",
   "metadata": {},
   "source": [
    "## Select Useful Features\n",
    "\n",
    "We only keep relevant columns from each dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e64a105",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = cases[[\"date\", \"cases_new\", \"cases_active\"]]\n",
    "deaths = deaths[[\"date\", \"deaths_new\"]]\n",
    "hospital = hospital.groupby(\"date\", as_index=False)[[\"admitted_covid\", \"hosp_covid\"]].sum()\n",
    "icu = icu.groupby(\"date\", as_index=False)[[\"icu_covid\", \"vent_covid\"]].sum()\n",
    "tests = tests.rename(columns={\"rtk-ag\": \"rtk_ag\"})[[\"date\", \"rtk_ag\", \"pcr\"]]\n",
    "vax = vax[[\n",
    "    \"date\", \"daily_partial\", \"daily_full\", \"daily_booster\",\n",
    "    \"cumul_partial\", \"cumul_full\", \"cumul_booster\"\n",
    "]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50370341",
   "metadata": {},
   "source": [
    "## Merge Datasets\n",
    "\n",
    "We merge all the datasets into a single DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e9cd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cases.merge(deaths, on=\"date\", how=\"left\")\n",
    "df = df.merge(hospital, on=\"date\", how=\"left\")\n",
    "df = df.merge(icu, on=\"date\", how=\"left\")\n",
    "df = df.merge(tests, on=\"date\", how=\"left\")\n",
    "df = df.merge(vax, on=\"date\", how=\"left\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2882c9f6",
   "metadata": {},
   "source": [
    "## Add Lag Features\n",
    "\n",
    "We add **7-day** and **14-day lag features** for trend analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbe8a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_features = [\n",
    "    \"cases_new\", \"cases_active\", \"admitted_covid\", \"hosp_covid\",\n",
    "    \"icu_covid\", \"vent_covid\", \"rtk_ag\", \"pcr\",\n",
    "    \"daily_partial\", \"daily_full\", \"daily_booster\",\n",
    "    \"cumul_partial\", \"cumul_full\", \"cumul_booster\"\n",
    "]\n",
    "\n",
    "for col in lag_features:\n",
    "    df[f\"{col}_lag7\"] = df[col].shift(7)\n",
    "    df[f\"{col}_lag14\"] = df[col].shift(14)\n",
    "\n",
    "# Drop rows with NaN (from lagging)\n",
    "df = df.dropna().reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7002375a",
   "metadata": {},
   "source": [
    "## Filter Date Range\n",
    "\n",
    "We keep only data between **15 July 2021** and **15 January 2022**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a18ab09",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = \"2021-07-15\"\n",
    "end_date   = \"2022-01-15\"\n",
    "\n",
    "df = df[(df[\"date\"] >= start_date) & (df[\"date\"] <= end_date)].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c75a56b",
   "metadata": {},
   "source": [
    "## Shuffle Rows\n",
    "\n",
    "We shuffle rows to remove any chronological ordering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ecb18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a87769",
   "metadata": {},
   "source": [
    "## Split into 6 Parts\n",
    "\n",
    "We divide the dataset into **6 equal parts**:\n",
    "- **5 parts for training**\n",
    "- **1 part for testing**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef8d360",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(df)\n",
    "split_size = n // 6\n",
    "\n",
    "splits = [df[i*split_size:(i+1)*split_size] for i in range(5)]\n",
    "splits.append(df[5*split_size:])  # last split takes remainder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fef8921",
   "metadata": {},
   "source": [
    "## Save to CSV Files\n",
    "\n",
    "We save:\n",
    "- `set_1.csv` to `set_5.csv` → inside **training_set/**\n",
    "- `set_6.csv` → inside **testing_set/**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d247588a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"training_set\", exist_ok=True)\n",
    "os.makedirs(\"testing_set\", exist_ok=True)\n",
    "\n",
    "for i, split in enumerate(splits, 1):\n",
    "    if i < 6:\n",
    "        split.to_csv(f\"training_set/set_{i}.csv\", index=False)\n",
    "    else:\n",
    "        split.to_csv(f\"testing_set/set_{i}.csv\", index=False)\n",
    "\n",
    "print(\"✅ Data successfully split and saved!\")\n",
    "print(f\"Training sets: {split_size*5} rows, Testing set: {len(splits[-1])} rows\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
